{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from player import Player\n",
    "from deck import Deck\n",
    "from game import Game\n",
    "# import plot\n",
    "\n",
    "def random_policy():\n",
    "    return 0 if random.random() < 0.5 else 1\n",
    "\n",
    "def epsilon_greedy_policy(epsilon, value_function, player, dealer):\n",
    "    # exploration\n",
    "    if random.random() < epsilon:\n",
    "        return random_policy()\n",
    "    # exploitation\n",
    "    else:\n",
    "        return best_policy(epsilon, value_function, player, dealer)\n",
    "\n",
    "def best_policy(epsilon, value_function, player, dealer):\n",
    "    value_HIT = value_function[(player, dealer, 0)]\n",
    "    value_STICK = value_function[(player, dealer, 1)]\n",
    "\n",
    "    if value_HIT > value_STICK:\n",
    "        return 0\n",
    "    elif value_STICK > value_HIT:\n",
    "        return 1\n",
    "    else:\n",
    "        return random_policy()\n",
    "\n",
    "def iteration(iterations, update, Name, policy, n_zero=100):\n",
    "\n",
    "    # (player, dealer, action) key\n",
    "    value_function = defaultdict(float)\n",
    "    # (player, dealer) key\n",
    "    counter_state = defaultdict(int)\n",
    "    # (player, dealer, action) key\n",
    "    counter_state_action = defaultdict(int)\n",
    "    # number of wins\n",
    "    wins1 = 0\n",
    "    wins2 = 0\n",
    "    winrecord1 = []\n",
    "    winrecord2 = []\n",
    "\n",
    "    for j in range(iterations):\n",
    "        # create a new random starting state\n",
    "        game = Game()\n",
    "        player1 = game.player1points\n",
    "        player2 = game.player2points\n",
    "        dealer = game.dealerpoints\n",
    "        action1 = None\n",
    "        action2 = None\n",
    "        reward1 = None\n",
    "        reward2 = None\n",
    "        # play a round\n",
    "        observed_keys1 = []\n",
    "        observed_keys2 = []\n",
    "        while not game.terminal:\n",
    "\n",
    "            if len(game.deck.contents) < 52 * 0.6:\n",
    "                game.deck = Deck()\n",
    "                game.deck.shuffle()\n",
    "            # find an action defined by the policy\n",
    "            if action1 is not 1 and reward1 is not -1:\n",
    "                epsilon = n_zero / float(n_zero + counter_state[(player1, dealer)])\n",
    "                action1 = policy(epsilon, value_function, player1, dealer)\n",
    "\n",
    "            else:\n",
    "                action1 = 1\n",
    "                action2 = random_policy()\n",
    "\n",
    "            if (player1, dealer, action1) not in observed_keys1 and player1 <=21:\n",
    "                observed_keys1.append((player1, dealer, action1))\n",
    "            if (player2, dealer, action2) not in observed_keys2 and action2 is not None:\n",
    "                observed_keys2.append((player2, dealer, action2))\n",
    "\n",
    "            # take a step\n",
    "            [player1, player2, dealer, reward1, reward2] = Game.step(game, player1, player2, dealer, action1, action2, reward1, reward2)\n",
    "\n",
    "        # we have reached an end of episode\n",
    "        update(reward1, reward2, observed_keys1, observed_keys2, counter_state, counter_state_action, value_function)\n",
    "\n",
    "        if j > iterations * 0.8:\n",
    "            if reward1 == 1:\n",
    "                wins1 += 1\n",
    "            if reward2 == 1:\n",
    "                wins2 += 1\n",
    "\n",
    "        winrecord1.append(reward1)\n",
    "        winrecord2.append(reward2)\n",
    "\n",
    "    print(Name + 'Wins: %.4f%%' % ((float(wins1) / (iterations * 0.2)) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MC(reward1, reward2, observed_keys1, observed_keys2, counter_state, counter_state_action, value_function):\n",
    "    if reward1 is not None:\n",
    "        # update over all keys\n",
    "        for key in observed_keys1:\n",
    "            # update counts\n",
    "            counter_state[key[:-1]] += 1\n",
    "            counter_state_action[key] += 1\n",
    "\n",
    "            # update value function\n",
    "            alpha = 1.0 / counter_state_action[key]\n",
    "            value_function[key] += alpha * (reward1 - value_function[key])\n",
    "\n",
    "    if reward2 is not None:\n",
    "        # update over all keys\n",
    "        for key in observed_keys2:\n",
    "            # update counts\n",
    "            counter_state[key[:-1]] += 1\n",
    "            counter_state_action[key] += 1\n",
    "\n",
    "            # update value function\n",
    "            alpha = 1.0 / counter_state_action[key]\n",
    "            value_function[key] += alpha * (reward2 - value_function[key])\n",
    "\n",
    "def QL(reward1, reward2, observed_keys1, observed_keys2, counter_state, counter_state_action, value_function):\n",
    "    if reward1 is not None:\n",
    "        # update over all keys\n",
    "        for i in range(len(observed_keys1)):\n",
    "            # update counts\n",
    "            counter_state[observed_keys1[i][:-1]] += 1\n",
    "            counter_state_action[observed_keys1[i]] += 1\n",
    "\n",
    "            # update value function\n",
    "            alpha = 1.0 / counter_state_action[observed_keys1[i]]\n",
    "            old = value_function[observed_keys1[i]]\n",
    "            if i < len(observed_keys1) - 1:\n",
    "                hit = observed_keys1[i+1][:2] + (1, )\n",
    "                stick = observed_keys1[i+1][:2] + (0, )\n",
    "                maxvalue = max(value_function[hit],value_function[stick])\n",
    "                new = 0.8 * maxvalue\n",
    "            else:\n",
    "                new = 0\n",
    "            value_function[observed_keys1[i]] = (1-alpha) * old + alpha * (reward1 + new)\n",
    "\n",
    "    if reward2 is not None:\n",
    "        # update over all keys\n",
    "        for i in range(len(observed_keys2)):\n",
    "            # update counts\n",
    "            counter_state[observed_keys2[i][:-1]] += 1\n",
    "            counter_state_action[observed_keys2[i]] += 1\n",
    "\n",
    "            # update value function\n",
    "            alpha = 1.0 / counter_state_action[observed_keys2[i]]\n",
    "            old = value_function[observed_keys2[i]]\n",
    "            if i < len(observed_keys2) - 1:\n",
    "                hit = observed_keys2[i+1][:2] + (1, )\n",
    "                stick = observed_keys2[i+1][:2] + (0, )\n",
    "                maxvalue = max(value_function[hit],value_function[stick])\n",
    "                new = 0.8 * maxvalue\n",
    "            else:\n",
    "                new = 0\n",
    "            value_function[observed_keys2[i]] = (1-alpha) * old + alpha * (reward2 + new)\n",
    "\n",
    "def TD(reward1, reward2, observed_keys1, observed_keys2, counter_state, counter_state_action, value_function):\n",
    "    if reward1 is not None:\n",
    "        # update over all keys\n",
    "        for i in range(len(observed_keys1)):\n",
    "            # update counts\n",
    "            counter_state[observed_keys1[i][:-1]] += 1\n",
    "            counter_state_action[observed_keys1[i]] += 1\n",
    "\n",
    "            # update value function\n",
    "            alpha = 1.0 / counter_state_action[observed_keys1[i]]\n",
    "            old = value_function[observed_keys1[i]]\n",
    "            if i < len(observed_keys1) - 1:\n",
    "                new = 0.8 * value_function[observed_keys1[i+1]]\n",
    "            else:\n",
    "                new = 0\n",
    "            value_function[observed_keys1[i]] = (1-alpha) * old + alpha * (reward1 + new)\n",
    "\n",
    "    if reward2 is not None:\n",
    "        # update over all keys\n",
    "        for i in range(len(observed_keys2)):\n",
    "            # update counts\n",
    "            counter_state[observed_keys2[i][:-1]] += 1\n",
    "            counter_state_action[observed_keys2[i]] += 1\n",
    "\n",
    "            # update value function\n",
    "            alpha = 1.0 / counter_state_action[observed_keys2[i]]\n",
    "            old = value_function[observed_keys2[i]]\n",
    "            if i < len(observed_keys2) - 1:\n",
    "                new = 0.8 * value_function[observed_keys2[i+1]]\n",
    "            else:\n",
    "                new = 0\n",
    "            value_function[observed_keys2[i]] = (1-alpha) * old + alpha * (reward2 + new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC-epsilonWins: 44.4350%\n",
      "QL-epsilonWins: 44.1300%\n",
      "TD-epsilonWins: 43.1100%\n",
      "MC-bestWins: 45.7000%\n",
      "QL-bestWins: 45.0700%\n",
      "TD-bestWins: 44.1600%\n"
     ]
    }
   ],
   "source": [
    "winrecord_MC_epsilon = iteration(100000, MC, 'MC-epsilon', epsilon_greedy_policy)\n",
    "winrecord_QL_epsilon = iteration(100000, QL, 'QL-epsilon', epsilon_greedy_policy)\n",
    "winrecord_TD_epsilon = iteration(100000, TD, 'TD-epsilon', epsilon_greedy_policy)\n",
    "winrecord_MC_best = iteration(100000, MC, 'MC-best', best_policy)\n",
    "winrecord_QL_best = iteration(100000, QL, 'QL-best', best_policy)\n",
    "winrecord_TD_best = iteration(100000, TD, 'TD-best', best_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
