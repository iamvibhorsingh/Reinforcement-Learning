{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: [[ 0.9  0.1]\n",
      " [ 0.5  0.5]]\n",
      "T_3: [[ 0.844  0.156]\n",
      " [ 0.78   0.22 ]]\n",
      "T_50: [[ 0.83333333  0.16666667]\n",
      " [ 0.83333333  0.16666667]]\n",
      "T_100: [[ 0.83333333  0.16666667]\n",
      " [ 0.83333333  0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Declaring the Transition Matrix T\n",
    "T = np.array([[0.90, 0.10],\n",
    "              [0.50, 0.50]])\n",
    "\n",
    "#Obtaining T after 3 steps\n",
    "T_3 = np.linalg.matrix_power(T, 3)\n",
    "#Obtaining T after 50 steps\n",
    "T_50 = np.linalg.matrix_power(T, 50)\n",
    "#Obtaining T after 100 steps\n",
    "T_100 = np.linalg.matrix_power(T, 100)\n",
    "\n",
    "#Printing the matrices\n",
    "print(\"T: \" + str(T))\n",
    "print(\"T_3: \" + str(T_3))\n",
    "print(\"T_50: \" + str(T_50))\n",
    "print(\"T_100: \" + str(T_100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility of state (1,1): 0.7056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def return_state_utility(v, T, u, reward, gamma):\n",
    "    \"\"\"Return the state utility.\n",
    "\n",
    "    @param v the value vector\n",
    "    @param T transition matrix\n",
    "    @param u utility vector\n",
    "    @param reward for that state\n",
    "    @param gamma discount factor\n",
    "    @return the utility of the state\n",
    "    \"\"\"\n",
    "    action_array = np.zeros(4)\n",
    "    for action in range(0, 4):\n",
    "        action_array[action] = np.sum(np.multiply(u, np.dot(v, T[:,:,action])))\n",
    "    return reward + gamma * np.max(action_array)\n",
    "\n",
    "def main():\n",
    "    #Starting state vector\n",
    "    #The agent starts from (1, 1)\n",
    "    v = np.array([[0.0, 0.0, 0.0, 0.0, \n",
    "                   0.0, 0.0, 0.0, 0.0, \n",
    "                   1.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "    #Transition matrix loaded from file\n",
    "    #(It is too big to write here)\n",
    "    T = np.load(\"T.npy\")\n",
    "\n",
    "    #Utility vector\n",
    "    u = np.array([[0.812, 0.868, 0.918,   1.0,\n",
    "                   0.762,   0.0, 0.660,  -1.0,\n",
    "                   0.705, 0.655, 0.611, 0.388]])\n",
    "\n",
    "    #Defining the reward for state (1,1)\n",
    "    reward = -0.04\n",
    "    #Assuming that the discount factor is equal to 1.0\n",
    "    gamma = 1.0\n",
    "\n",
    "    #Use the Bellman equation to find the utility of state (1,1)\n",
    "    utility_11 = return_state_utility(v, T, u, reward, gamma)\n",
    "    print(\"Utility of state (1,1): \" + str(utility_11))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== FINAL RESULT ==================\n",
      "Iterations: 58\n",
      "Delta: 0\n",
      "Gamma: 0.9999999999999999\n",
      "Epsilon: 0.01\n",
      "===================================================\n",
      "[ 0.81155822  0.86780822  0.91780822  1.        ]\n",
      "[ 0.76155822  0.          0.66027397 -1.        ]\n",
      "[ 0.70530822  0.65530822  0.61141553  0.38792491]\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def return_state_utility(v, T, u, reward, gamma):\n",
    "    \"\"\"Return the state utility.\n",
    "\n",
    "    @param v the value vector\n",
    "    @param T transition matrix\n",
    "    @param u utility vector\n",
    "    @param reward for that state\n",
    "    @param gamma discount factor\n",
    "    @return the utility of the state\n",
    "    \"\"\"\n",
    "    action_array = np.zeros(4)\n",
    "    for action in range(0, 4):\n",
    "        action_array[action] = np.sum(np.multiply(u, np.dot(v, T[:,:,action])))\n",
    "    return reward + gamma * np.max(action_array)\n",
    "\n",
    "def main():\n",
    "    #Change as you want\n",
    "    tot_states = 12\n",
    "    gamma = 1 - 10**(-16.2)\n",
    "    #Discount factor\n",
    "    iteration = 0 #Iteration counter\n",
    "    epsilon = 0.01 #Stopping criteria small value\n",
    "\n",
    "    #List containing the data for each iteation\n",
    "    graph_list = list()\n",
    "\n",
    "    #Transition matrix loaded from file (It is too big to write here)\n",
    "    T = np.load(\"T.npy\")\n",
    "\n",
    "    #Reward vector\n",
    "    r = np.array([-0.04, -0.04, -0.04,  +1.0,\n",
    "                  -0.04,  0.0, -0.04,  -1.0,\n",
    "                  -0.04, -0.04, -0.04, -0.04])    \n",
    "\n",
    "    #Utility vectors\n",
    "    u = np.array([0.0, 0.0, 0.0,  0.0,\n",
    "                   0.0, 0.0, 0.0,  0.0,\n",
    "                   0.0, 0.0, 0.0,  0.0])\n",
    "    u1 = np.array([0.0, 0.0, 0.0,  0.0,\n",
    "                    0.0, 0.0, 0.0,  0.0,\n",
    "                    0.0, 0.0, 0.0,  0.0])\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "        u = u1.copy()\n",
    "        iteration += 1\n",
    "        graph_list.append(u)\n",
    "        for s in range(tot_states):\n",
    "            reward = r[s]\n",
    "            v = np.zeros((1,tot_states))\n",
    "            v[0,s] = 1.0\n",
    "            u1[s] = return_state_utility(v, T, u, reward, gamma)\n",
    "            delta = max(delta, np.abs(u1[s] - u[s])) #Stopping criteria       \n",
    "        if delta < epsilon * (1 - gamma) / gamma:\n",
    "                print(\"=================== FINAL RESULT ==================\")\n",
    "                print(\"Iterations: \" + str(iteration))\n",
    "                print(\"Delta: \" + str(delta))\n",
    "                print(\"Gamma: \" + str(gamma))\n",
    "                print(\"Epsilon: \" + str(epsilon))\n",
    "                print(\"===================================================\")\n",
    "                print(u[0:4])\n",
    "                print(u[4:8])\n",
    "                print(u[8:12])\n",
    "                print(\"===================================================\")\n",
    "                break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
